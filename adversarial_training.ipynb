{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZu3EiWNwP44"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torch.serialization import add_safe_globals\n",
        "\n",
        "# Custom dataset class to hold preprocessed image data\n",
        "class TaskDataset(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "        self.ids = []\n",
        "        self.imgs = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.imgs[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        # Convert non-RGB images to RGB\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "\n",
        "        # Apply transformation if provided\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "# Register custom class for loading serialized dataset\n",
        "add_safe_globals({'TaskDataset': TaskDataset})\n",
        "\n",
        "# Load the serialized dataset\n",
        "dataset = torch.load(\"/kaggle/input/traindata/Train.pt\", weights_only=False)\n",
        "\n",
        "# Define image transformations (resize and normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "dataset.transform = transform\n",
        "\n",
        "# Create data loader for batching\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# FGSM attack implementation\n",
        "def fgsm_attack(model, images, labels, epsilon):\n",
        "    images.requires_grad = True\n",
        "    outputs = model(images)\n",
        "    loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    # Add adversarial noise\n",
        "    return torch.clamp(images + epsilon * images.grad.sign(), 0, 1)\n",
        "\n",
        "# PGD attack implementation\n",
        "def pgd_attack(model, images, labels, epsilon=0.03, alpha=0.01, steps=3):\n",
        "    ori = images.clone().detach()\n",
        "    images = ori + 0.001 * torch.randn_like(ori)  # Random start\n",
        "    for _ in range(steps):\n",
        "        images.requires_grad = True\n",
        "        outputs = model(images)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        # Perform iterative update\n",
        "        images = images + alpha * images.grad.sign()\n",
        "        eta = torch.clamp(images - ori, min=-epsilon, max=epsilon)\n",
        "        images = torch.clamp(ori + eta, min=0, max=1).detach()\n",
        "    return images\n",
        "\n",
        "# Load and modify ResNet18 for 10-class classification\n",
        "model = models.resnet18(weights=None)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "\n",
        "# Move model to available device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training configuration\n",
        "epochs = 15\n",
        "epsilon = 0.03   # FGSM/PGD max perturbation\n",
        "alpha = 0.01     # PGD step size\n",
        "pgd_steps = 3    # PGD steps\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Clean loss\n",
        "        out_clean = model(images)\n",
        "        loss_clean = criterion(out_clean, labels)\n",
        "\n",
        "        # FGSM loss\n",
        "        images_fgsm = fgsm_attack(model, images, labels, epsilon)\n",
        "        out_fgsm = model(images_fgsm)\n",
        "        loss_fgsm = criterion(out_fgsm, labels)\n",
        "\n",
        "        # PGD loss\n",
        "        images_pgd = pgd_attack(model, images, labels, epsilon, alpha, pgd_steps)\n",
        "        out_pgd = model(images_pgd)\n",
        "        loss_pgd = criterion(out_pgd, labels)\n",
        "\n",
        "        # Combine and backpropagate\n",
        "        loss = (loss_clean + loss_fgsm + loss_pgd) / 3\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    print(f\"Epoch {epoch+1:3d}/{epochs} - Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"robust_model.pt\")\n",
        "print(\"Model saved as 'robust_model.pt'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Tests ####\n",
        "# (these are the assertions being ran on the eval endpoint for every submission)\n",
        "\n",
        "allowed_models = {\n",
        "    \"resnet18\": models.resnet18,\n",
        "    \"resnet34\": models.resnet34,\n",
        "    \"resnet50\": models.resnet50,\n",
        "}\n",
        "with open(\"/kaggle/working/robust_model.pt\", \"rb\") as f:\n",
        "    try:\n",
        "        model: torch.nn.Module = allowed_models[\"resnet18\"](weights=None)\n",
        "        model.fc = torch.nn.Linear(model.fc.weight.shape[1], 10)\n",
        "    except Exception as e:\n",
        "        raise Exception(\n",
        "            f\"Invalid model class, {e=}, only {allowed_models.keys()} are allowed\",\n",
        "        )\n",
        "    try:\n",
        "        state_dict = torch.load(f, map_location=torch.device(\"cpu\"))\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "        model.eval()\n",
        "        out = model(torch.randn(1, 3, 32, 32))\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Invalid model, {e=}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "el18c2Gaw5BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Submission ---\n",
        "import requests\n",
        "response = requests.post(\n",
        "    \"http://34.122.51.94:9090/robustness\",\n",
        "    files={\"file\": open(\"/kaggle/working/robust_model.pt\", \"rb\")},\n",
        "    headers={\"token\": \"12910150\", \"model-name\": \"resnet18\"}\n",
        ")\n",
        "print(\"Submission response:\", response.json())"
      ],
      "metadata": {
        "id": "KJou8wSrw60H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}